alldfs<-read.csv(file.choose())
library(rvest)
library(tidyverse)
library(sf)
library(patchwork)
library(ggstream)
library(ggtext)
alldfs<-as_tibble(alldfs)
# Add the map -------------------------------------------------------------
canada_cd <- st_read("C:/Users/jeffz/Desktop/data analysis projects/ontarioparks/canada_cd_sim.geojson", quiet = TRUE) # 1
canada_cd$PRNAME<-as.factor(canada_cd$PRNAME)
#crs_string = "+proj=lcc +lat_1=49 +lat_2=77 #+lon_0=-91.52 +x_0=0 +y_0=0 +datum=NAD83 +units=m #+no_defs" # 2
#transform ontariomap
alldfs<-alldfs %>% mutate(yearlab_long = -93,yearlab_lat = 46)
mypoints<-alldfs %>% st_as_sf(coords = c("long", "lat"), crs = 4326) %>%
st_transform(crs = 4326)
addlabel<-alldfs %>% st_as_sf(coords = c("yearlab_long", "yearlab_lat"), crs = 4326) %>%
st_transform(crs = 4326)
ontario<- canada_cd[canada_cd$PRNAME=="Ontario",] %>% st_transform(crs = 4326)
mypoints<-na.omit(mypoints)
mypoints$
alldfs$regionclean<-NA
alldfs$regionclean<-alldfs$url
alldfs$regionclean<-gsub("https://en.wikipedia.org/wiki/List_of_provincial_parks_of_Northern_Ontario","Northern Ontario", alldfs$regionclean)
alldfs$regionclean<-gsub("https://en.wikipedia.org/wiki/List_of_provincial_parks_of_Southwestern_Ontario","Southwestern Ontario", alldfs$regionclean)
alldfs$regionclean<-gsub("https://en.wikipedia.org/wiki/List_of_provincial_parks_of_Central_Ontario","Central Ontario", alldfs$regionclean)
alldfs$regionclean<-gsub("https://en.wikipedia.org/wiki/List_of_provincial_parks_of_Eastern_Ontario","Eastern Ontario", alldfs$regionclean)
alldfs$regionclean<-gsub("https://en.wikipedia.org/wiki/List_of_provincial_parks_of_the_Golden_Horseshoe","Golden Horseshoe", alldfs$regionclean)
mypoints$regionclean<-NA
mypoints$regionclean<-mypoints$url
mypoints$regionclean<-gsub("https://en.wikipedia.org/wiki/List_of_provincial_parks_of_Northern_Ontario","Northern Ontario", mypoints$regionclean)
mypoints$regionclean<-gsub("https://en.wikipedia.org/wiki/List_of_provincial_parks_of_Southwestern_Ontario","Southwestern Ontario", mypoints$regionclean)
mypoints$regionclean<-gsub("https://en.wikipedia.org/wiki/List_of_provincial_parks_of_Central_Ontario","Central Ontario", mypoints$regionclean)
mypoints$regionclean<-gsub("https://en.wikipedia.org/wiki/List_of_provincial_parks_of_Eastern_Ontario","Eastern Ontario", mypoints$regionclean)
mypoints$regionclean<-gsub("https://en.wikipedia.org/wiki/List_of_provincial_parks_of_the_Golden_Horseshoe","Golden Horseshoe", mypoints$regionclean)
alldfs$regionclean<-factor(alldfs$regionclean, levels = c("Northern Ontario",
"Central Ontario",
"Southwestern Ontario",
"Eastern Ontario",
"Golden Horseshoe"))
mypoints$regionclean<-factor(mypoints$regionclean, levels = c("Northern Ontario",
"Central Ontario",
"Southwestern Ontario",
"Eastern Ontario",
"Golden Horseshoe"))
ontariomap<-ggplot(data = mypoints) +
geom_sf(aes(fill = regionclean), size = 0.1,
data = ontario,
fill = alpha("#0075bf",0.25),
col = "black") +
labs(x = "", y = "")+
#theme_bw()+
#geom_text(aes(x = -90, y = 46, aes(label = Established)))+
geom_sf(data = mypoints, aes(fill = regionclean), shape = 21)+#fill = "#00ab67"
theme(axis.text = element_blank(),
panel.border = element_rect(colour = "white", fill=NA, size = 5),
panel.background = element_rect(fill = "white"),
panel.grid = element_blank(),
legend.position = "none",
axis.ticks = element_blank(),
plot.background = element_rect(fill = "white", colour = NA))+
annotate("text",x = -90, y =45, label = "")
ontariomap
#ggplot(data = world) +
#    geom_sf() +
#    geom_sf(data = sites, size = 4, shape = 23, fill = "darkred") +
#    coord_sf(xlim = c(-88, -78), ylim = c(24.5, 33), expand = FALSE)
ontariomap+geom_density2d_filled()
View(mypoints)
library(rvest)
library(tidyverse)
library(sf)
library(patchwork)
library(ggstream)
library(ggtext)
sysfonts::font_add_google(name = "Lato", "Lato")
showtext::showtext_auto()
#links
baseurl<-"https://en.wikipedia.org/wiki/List_of_provincial_parks_of_"
SWO<-"Southwestern_Ontario"
NO<-"Northern_Ontario"
CO<-"Central_Ontario"
EO<-"Eastern_Ontario"
GH<-"the_Golden_Horseshoe"
#sequence of url strings
urlend<-c(SWO,NO,CO,EO,GH)#short name used for assigning
fullurl<-paste0(baseurl,urlend)#full name for webscraping
index<-5
#sequence of url strings
urlend<-c(SWO,NO,CO,EO,GH)#short name used for assigning
fullurl<-paste0(baseurl,urlend)#full name for webscraping
index<-1
#read HTML content from url
content <- read_html(fullurl[index])
#read all tables on the page, and parse into dataframes
tables<- content %>% html_nodes("table") %>% html_table(fill = TRUE)
#remove tables that contain don't tables we want.
#keep only ones that have 'name' as a column
nameslist<-lapply(tables,names)
tableswithoutdata<-which(grepl("Name",nameslist))
tables<-tables[tableswithoutdata]
#get the inner text from the table of contents
#select divs with class 'toc'.
#within this, select ul tag
#each ul has a nested a tag, select this
#get the inner text
toc<-content %>% html_nodes("div#toc") %>% html_nodes("ul") %>% html_nodes("a") %>% html_text()
#
#eastern ontario page missing table of contents (single table)
#toc<-"Eastern Ontario"
#toc<-"Golden Horseshoe"
if(length(tables)==length(toc)){
print("tables and TOC are same length")
} else {
print("tables and toc are not the same length")
}
tables_clean<-lapply(tables, function(y) y %>% select(Name,Established,Coordinates))
tabs_w_region<-purrr::map2(tables_clean, toc, ~ mutate(.x, region = .y, url = fullurl[index]))
#flatten the list of dataframes into one dataframe
flattened<-tabs_w_region %>% bind_rows()
#get decimal lat/long, and split up lat/long
flattened$decimal<-str_split_fixed(flattened$Coordinates, pattern = " / ", n = Inf)[,3]
flattened$lat<-as.numeric(str_split_fixed(flattened$decimal, pattern = ";", n = Inf)[,1])
flattened$long<-as.numeric(str_split_fixed(flattened$decimal, pattern = ";", n = Inf)[,2])
print("single table created")
assign(urlend[index],flattened)
print(paste0(urlend[index], " df created"))
alldfs<-bind_rows(Northern_Ontario,
Southwestern_Ontario,
Central_Ontario,
Eastern_Ontario,
the_Golden_Horseshoe, .id = "url_region")
